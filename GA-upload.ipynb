{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ed80b-1167-4284-b1b7-80693fe84d7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os  \n",
    "import seaborn as sns  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import random\n",
    "\n",
    "# Define filenames for Ada, DT, J48, KNN, MLP, NB, RF, SVM, and XGB\n",
    "GAnumber = \"GA4\" #Name the output file\n",
    "\n",
    "Group = \"_ALL\"  #Name the output file\n",
    "\n",
    "Y_output = \"TMT\"\n",
    "\n",
    "\n",
    "# Load data path\n",
    "base_dir     = \"C:/Users/User/Desktop\"\n",
    "file_name = \"CTMT_clean_c_lable_upload.CSV\"  # Name of the file to read\n",
    "encoding_fmt = \"ISO-8859-1\"\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "seed_ML = 42\n",
    "seed_CV = 42 #any number\n",
    "\n",
    "# Set GA parameter variables\n",
    "POP_SIZE = 30\n",
    "GENS = 30\n",
    "CX_PB = 0.5\n",
    "MUT_PB = 0.3\n",
    "SEED = 42\n",
    "\n",
    "# Set custom save path \n",
    "folder_name = f\"{GAnumber}{Group}({Y_output})\"\n",
    "custom_results_dir = f\"C:/Users/User/Desktop/{folder_name}\"  # You can modify this path\n",
    "\n",
    "data_source_Ada = Y_output + \"_Ada\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_Ada = \"Ada_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_GB = Y_output + \"_GB\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_GB = \"GB_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_DT = Y_output + \"_DT\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_DT = \"DT_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_J48 = Y_output + \"_J48\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_J48 = \"J48_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_KNN = Y_output + \"_KNN\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_KNN = \"KNN_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_MLP = Y_output + \"_MLP\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_MLP = \"MLP_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_NB = Y_output + \"_NB\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_NB = \"NB_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_RF = Y_output + \"_RF\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_RF = \"RF_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_SVM = Y_output + \"_SVM\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_SVM = \"SVM_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "data_source_XGB = Y_output + \"_XGB\" + Group + \"_clean_nu_\" + \".csv\"\n",
    "output_filename_XGB = \"XGB_\" + GAnumber + Group + \".csv\"\n",
    "\n",
    "# Build the full path first, then load files via data_path\n",
    "data_path = os.path.join(base_dir, file_name)\n",
    "\n",
    "# Initialize results list\n",
    "results_data = []\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(custom_results_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(custom_results_dir, \"models\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(custom_results_dir, \"figures\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(custom_results_dir, \"text\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba364a-5fa9-4840-810e-662d3c627f9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#GradientBoostingClassifier\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "# Reconstruct X and y\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "# Perform label encoding on categorical columns[\"GENDER\", \"Eeducation\", \"Smoke\", \"Drink\", \"SelfHealth\", \"SelfHappiness\", \"EX_TYPE\", \"OPEN_CLOSE\"]\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "# Calculate and display the number of features\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\nCategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\nContinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "# Save the standardized dataset to a new CSV file\n",
    "# Add the target variable back to the dataset first\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "# Specify save path\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_GB )\n",
    "\n",
    "# Save as CSV file\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "# Estimator: GB accuracy\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = GradientBoostingClassifier(random_state=seed_ML)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),  \n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "Ôºâ\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_GB.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "# Grid Search\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Perform 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Perform 5-fold cross-validation with the optimal parameters and calibration, and collect performance metrics\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "# Store metrics for each fold\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    # Train uncalibrated model\n",
    "    clf = GradientBoostingClassifier(**best_params, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    # Calibrate model\n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    # Validate and compute metrics\n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "    \n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "# CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"GB_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc4d1c-94f6-4e20-a9a7-d5d865b2baf6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ramdom Forest\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_RF)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "# Random Forest\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=seed_ML)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_RF.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "# Perform hyperparameter tuning via Grid Search\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform 5-fold stratified cross-validation\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "   \n",
    "    clf = RandomForestClassifier(**best_params, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "# CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"RF_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2ddec-be23-43cc-b23f-af1186bd8967",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "#\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        \n",
    "        dummies = pd.get_dummies(X[col], prefix=col, drop_first=True).astype(int)\n",
    "        \n",
    "        X = X.drop(col, axis=1)\n",
    "        \n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "\n",
    "\n",
    "continuous_cols = [col for col in X.columns if not any(cat_col in col for cat_col in categorical_cols)]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n",
    "\n",
    "\n",
    "joblib.dump(scaler, os.path.join(custom_results_dir, \"models\", \"standard_scaler_SVM.pkl\"))\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_SVM)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "# SVM\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = SVC(random_state=seed_ML)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA:\\n\")\n",
    "print(f\"(Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_SVM.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    #'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    #'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(SVC(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = SVC(**best_params, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "  \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "# CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"SVM_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb211cba-ba20-4a2e-ba9b-028e352b8119",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_XGB)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "# XGBoost\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = xgb.XGBClassifier(random_state=seed_ML)  #  XGBoost\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "Ôºâ\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_XGB.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = xgb.XGBClassifier(**best_params, random_state=seed_ML, n_jobs=1)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "#  CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"XGB_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3799823-d4b6-48ef-aab6-92b45887d270",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_Ada )\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = AdaBoostClassifier(algorithm='SAMME', random_state=seed_ML)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),  \n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_Ada.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'algorithm': ['SAMME']  \n",
    "}\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "   \n",
    "    clf = AdaBoostClassifier(**best_params, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "   \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Compute mean and standard deviationÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "    \n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "# CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"Ada_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f7e44-fcad-48fc-a523-913b44f6d08f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_DT)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "# Decision Tree \n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = DecisionTreeClassifier(random_state=seed_ML)  # ÊîπÁÇ∫ DecisionTreeClassifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_DT.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state= seed_ML), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = DecisionTreeClassifier(**best_params, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"DT_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d45d4-cebe-486e-a8d9-bc0ac3f82b56",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        \n",
    "        dummies = pd.get_dummies(X[col], prefix=col, drop_first=True).astype(int)\n",
    "       \n",
    "        X = X.drop(col, axis=1)\n",
    "        \n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "\n",
    "\n",
    "continuous_cols = [col for col in X.columns if not any(cat_col in col for cat_col in categorical_cols)]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n",
    "\n",
    "\n",
    "joblib.dump(scaler, os.path.join(custom_results_dir, \"models\", \"standard_scaler.pkl\"))\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_KNN)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "#KNN\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = KNeighborsClassifier()  \n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_KNN.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],  \n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = KNeighborsClassifier(**grid_search.best_params_)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "# CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"KNN_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be955d5-36c2-451b-be72-7a263891e7f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_NB)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_NB.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "# NB\n",
    "print(\"\\nNB ...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "    \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "#  CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"NB_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fda71-0f1d-405e-ad35-30e3e95d03d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MLP\n",
    "\n",
    "df = pd.read_csv(data_path, encoding=encoding_fmt)\n",
    "\n",
    "\n",
    "y = df[\"TMT\"].values\n",
    "X = df.drop(columns=[\"TMT\"])\n",
    "\n",
    "\n",
    "categorical_cols = [\"GEN\", \"Edu\", \"Smoke\", \"Drink\", \"S-HLTH\", \"S-HAP\", \"EX_TYPE\", \"O/C\"]\n",
    "for col in categorical_cols:\n",
    "    if col in X.columns:\n",
    "        \n",
    "        dummies = pd.get_dummies(X[col], prefix=col, drop_first=True).astype(int)\n",
    "        \n",
    "        X = X.drop(col, axis=1)\n",
    "        \n",
    "        X = pd.concat([X, dummies], axis=1)\n",
    "\n",
    "\n",
    "continuous_cols = [col for col in X.columns if not any(cat_col in col for cat_col in categorical_cols)]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X[continuous_cols] = scaler.fit_transform(X[continuous_cols])\n",
    "\n",
    "\n",
    "joblib.dump(scaler, os.path.join(custom_results_dir, \"models\", \"standard_scaler.pkl\"))\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X.columns if any(cat_col in col for cat_col in categorical_cols)]\n",
    "continuous_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nTotal number of featuresÔºö{len(X.columns)}\")\n",
    "print(f\"Number of categorical featuresÔºö{len(categorical_features)}\")\n",
    "print(f\"Number of continuous featuresÔºö{len(continuous_features)}\")\n",
    "print(\"\\ncategorical featuresÔºö\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"- {feat}\")\n",
    "print(\"\\ncontinuous featuresÔºö\")\n",
    "for feat in continuous_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "\n",
    "processed_df = pd.concat([X, pd.Series(y, name=\"TMT\")], axis=1)\n",
    "\n",
    "\n",
    "processed_data_path = os.path.join(custom_results_dir, data_source_MLP)\n",
    "\n",
    "\n",
    "processed_df.to_csv(processed_data_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Standardized dataset saved toÔºö{processed_data_path}\")\n",
    "\n",
    "X_np = X.values\n",
    "feature_names = X.columns.tolist()\n",
    "num_features = X_np.shape[1]\n",
    "\n",
    "def evaluate(individual):\n",
    "    if sum(individual) == 0:\n",
    "        return 0.0,\n",
    "    selected_idx = [i for i, bit in enumerate(individual) if bit == 1]\n",
    "    X_sel = X_np[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)\n",
    "    clf = MLPClassifier(\n",
    "        random_state=seed_ML,\n",
    "        max_iter=3000,\n",
    "        learning_rate_init=0.01,\n",
    "        tol=1e-4\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test),\n",
    "\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "pop = toolbox.population(n=POP_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=CX_PB, mutpb=MUT_PB, ngen=GENS, halloffame=hof, verbose=True)\n",
    "\n",
    "Ôºâ\n",
    "print(\"\\nüîß GA :\\n\")\n",
    "print(f\" (Population Size): {POP_SIZE}\")\n",
    "print(f\" (Generations): {GENS}\")\n",
    "print(f\" (Crossover Probability): {CX_PB}\")\n",
    "print(f\" (Mutation Probability): {MUT_PB}\")\n",
    "print(f\" (Random Seed): {SEED}\")\n",
    "print(f\" (Selection): Tournament (tournsize=3)\")\n",
    "print(f\" (Crossover): Two-point crossover\")\n",
    "print(f\" (Mutation): Flip bit (indpb=0.05)\")\n",
    "\n",
    "\n",
    "best_individual = hof[0]\n",
    "selected_features = [feature_names[i] for i in range(num_features) if best_individual[i] == 1]\n",
    "print(\"\\n‚úÖ Selected features:\")\n",
    "for feat in selected_features:\n",
    "    print(f\"- {feat}\")\n",
    "\n",
    "selected_features_df = pd.DataFrame({'Selected_Features': selected_features})\n",
    "selected_features_path = os.path.join(custom_results_dir, \"text\", \"Selected_Features_MLP.csv\")\n",
    "os.makedirs(os.path.dirname(selected_features_path), exist_ok=True)\n",
    "selected_features_df.to_csv(selected_features_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\n‚úÖ Selected features saved toÔºö{selected_features_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nüîç Perform hyperparameter tuning via Grid Search...\")\n",
    "X_selected = X[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1], \n",
    "    'max_iter': [3000, 5000],  \n",
    "    'tol': [1e-4, 1e-3]  \n",
    "}\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    MLPClassifier(\n",
    "        random_state=seed_ML,\n",
    "        max_iter=5000,\n",
    "    ),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Optimal parameter set:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "cv = StratifiedKFold(n_splits, shuffle=True, random_state= seed_CV)\n",
    "grid_search = GridSearchCV(\n",
    "    MLPClassifier(\n",
    "        random_state=seed_ML,\n",
    "        max_iter=3000,\n",
    "        learning_rate_init=0.01,\n",
    "        tol=1e-4\n",
    "    ),\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_CV)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'recall': [],\n",
    "    'precision': [],\n",
    "    'mcc': []\n",
    "}\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_selected, y)):\n",
    "    X_tr = X_selected.iloc[train_idx]\n",
    "    X_val = X_selected.iloc[val_idx]\n",
    "    y_tr = y[train_idx]\n",
    "    y_val = y[val_idx]\n",
    "\n",
    "    \n",
    "    clf = MLPClassifier(**grid_search.best_params_, random_state=seed_ML)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    calibrator = CalibratedClassifierCV(clf, cv='prefit', method='sigmoid')\n",
    "    calibrator.fit(X_tr, y_tr)\n",
    "\n",
    "    \n",
    "    y_pred = calibrator.predict(X_val)\n",
    "    metrics['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    metrics['f1'].append(f1_score(y_val, y_pred))\n",
    "    metrics['recall'].append(recall_score(y_val, y_pred))\n",
    "    metrics['precision'].append(precision_score(y_val, y_pred))\n",
    "    metrics['mcc'].append(matthews_corrcoef(y_val, y_pred))\n",
    "\n",
    "\n",
    "print(\"üéØ 5-Fold Mean and standard deviation of calibrated model metricsÔºö\")\n",
    "for name, vals in metrics.items():\n",
    "    mean_val = np.mean(vals)\n",
    "    std_val = np.std(vals)\n",
    "    print(f\"{name.capitalize():<10}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "  \n",
    "    results_data.append({\n",
    "        'Fold': 'Mean ¬± Std',\n",
    "        'Metric': name.capitalize(),\n",
    "        'Mean': f\"{mean_val:.4f}\",\n",
    "        'Std': f\"{std_val:.4f}\"\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(n_splits):\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'Accuracy',   'Mean': metrics['accuracy'][i],   'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",\n",
    "        'Metric': 'F1',         'Mean': metrics['f1'][i],         'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Recall',     'Mean': metrics['recall'][i],     'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'Precision',  'Mean': metrics['precision'][i],  'Std': ''\n",
    "    })\n",
    "    results_data.append({\n",
    "        'Fold': f\"Fold {i+1}\",  'Metric': 'MCC',        'Mean': metrics['mcc'][i],        'Std': ''\n",
    "    })\n",
    "\n",
    "#  CSV\n",
    "result_df = pd.DataFrame(results_data)\n",
    "csv_save_path = os.path.join(custom_results_dir, \"text\", \"MLP_Fold_Calibration_Results.csv\")\n",
    "result_df.to_csv(csv_save_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Results saved toÔºö{csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f58d0e-3365-4748-9420-b7b8ac328e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
